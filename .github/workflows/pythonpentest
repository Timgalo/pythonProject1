import scrapy
import requests

#Performing a 'GET' request to the specified web page.

url = input(str('Enter a url'))
r = requests.get(url)


if r.ok:
        print(r.text)
else:
        print('Bad Response!')

print("Status code:")
print("\t *", r.status_code)    #Returning the 'OK' status code
print(r.status_code)

if r.status_code != 200:
    print('Invalid url or webpage not available')
else:
    print('OK!')

h = requests.head(url)
print("Header:")
print("**********")                 #Retrieving the web-page header

for x in h.headers:
    print("\t ", x, ":", h.headers[x])
print("**********")


headers = {'User-Agent' : 'Mobile'}         #Changing the user-agent to 'Mobile'
rh = requests.get(url, headers=headers)
print(rh.text)



class NewSpider(scrapy.Spider):
        name = "new_spider"                     #Creating a spider to scrape the web page for images
        start_urls\
                = [
                'http://172.18.58.238/'
        ]
        def parse(self, response):
                css_selector = 'img'
                for x in response.css(css_selector):
                        newsel = '@src'
                        yield {
                                'Image Link': x.xpath(newsel).extract_first(),
                        }
                        Page_selector = '.next a ::attr(href)'
                        next_page = response.css(Page_selector).extract_first()
                        if next_page:
                                yield scrapy.Request(
                                        response.urljoin(next_page),
                                        callback=self.parse()

                        )
